{
 "metadata": {
  "name": "",
  "signature": "sha256:1cd2ece08d06d387c663e4d93a0eaa48fbab9ba3c9dc8df97290aff53d07e80f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# code to regenerate input files for results for paper\n",
      "#\n",
      "# http://www.fabiangieseke.de/pdfs/neucom2013_draft.pdf\n",
      "#  see Table 2 results real-sim data set\n",
      "#\n",
      "# see also: \n",
      "#  http://www.fabiangieseke.de/pdfs/icpram2012.pdf\n",
      "# \n",
      "import sys\n",
      "from time import time\n",
      "from pprint import pprint\n",
      "\n",
      "import numpy as np\n",
      "import scipy\n",
      "import scipy.sparse as sp\n",
      "import joblib\n",
      "\n",
      "import io\n",
      "import os.path\n",
      "\n",
      "import sklearn\n",
      "import sklearn.svm\n",
      "import sklearn.datasets\n",
      "import sklearn.metrics\n",
      "import sklearn.cross_validation\n",
      "\n",
      "\n",
      "from sklearn.externals.six import u, b\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X, y = sklearn.datasets.load_svmlight_file('real-sim')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "(72309, 20958)"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "Counter(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "Counter({-1.0: 50071, 1.0: 22238})"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "splits = sklearn.cross_validation.StratifiedShuffleSplit(y, n_iter=1, test_size=0.50)\n",
      "train_indices, test_indices = splits.__iter__().next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "instance_ids = np.arange(y.size)\n",
      "X_train = X[train_indices]\n",
      "train_ids = instance_ids[train_indices]\n",
      "\n",
      "X_test = X[test_indices]\n",
      "test_ids = instance_ids[test_indices]\n",
      "\n",
      "train_labels = y[train_indices]\n",
      "test_labels = y[test_indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svm = sklearn.svm.LinearSVC(penalty='l2', C=10, dual=False)\n",
      "svm.fit(X_train, train_labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "LinearSVC(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
        "     intercept_scaling=1, loss='l2', multi_class='ovr', penalty='l2',\n",
        "     random_state=None, tol=0.0001, verbose=0)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy = sklearn.metrics.accuracy_score(test_labels, svm.predict(X_test))\n",
      "print 100.0*(1.0-accuracy)\n",
      "#ncv = 10\n",
      "#print sklearn.cross_validation.cross_val_score(svm, X_train, train_labels, cv=10).sum()/ncv\n",
      "#print sklearn.cross_validation.cross_val_score(svm, X_test, test_labels, cv=10).sum()/ncv\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.39648734615\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X_train.shape\n",
      "print X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(36154, 20958)\n",
        "(36155, 20958)\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_svmlight_infiles(L, y_l, U, y_u, HO, y_ho):\n",
      "\n",
      "    A = scipy.sparse.vstack((L,U))\n",
      "    unk_l = y_u*0   \n",
      "    a_l = np.hstack((y_l, unk_l))\n",
      "    print A.shape, a_l.shape \n",
      "    numL = L.shape[0] \n",
      "    \n",
      "    training_file = 'svmlight.train.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(A,a_l,training_file,zero_based=False)\n",
      "    \n",
      "    testL_file = 'svmlight.testL.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(L,y_l,testL_file,zero_based=False)\n",
      "    \n",
      "    testU_file = 'svmlight.testU.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(U,y_u,testU_file,zero_based=False)\n",
      "    \n",
      "    testHO_file = 'svmlight.testHO.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(HO,y_ho,testHO_file,zero_based=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dump_svmlin(X, y, fX, fy):\n",
      "    X_value_pattern = u(\"%d:%.16g\")\n",
      "    X_line_pattern = u(\" %s\\n\")\n",
      "    y_line_pattern = u(\"%d\")\n",
      "    \n",
      "    is_sp = int(hasattr(X, \"tocsr\"))\n",
      "\n",
      "    for i in range(X.shape[0]):\n",
      "        if is_sp:\n",
      "            span = slice(X.indptr[i], X.indptr[i + 1])\n",
      "            row = zip(X.indices[span], X.data[span])\n",
      "        else:\n",
      "            nz = X[i] != 0\n",
      "            row = zip(np.where(nz)[0], X[i, nz])\n",
      "\n",
      "        s = \" \".join(X_value_pattern % (j + 1, x) for j, x in row)\n",
      "        fX.write((X_line_pattern % s).encode('ascii'))\n",
      "        fy.write((y_line_pattern % y[i]).encode('ascii'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_svmlin_infiles(L, y_l, U, y_u, HO, y_ho):\n",
      "    print \"print_svmlin_infiles...\"\n",
      "    A = scipy.sparse.vstack((L,U))\n",
      "    unk_l = y_u*0\n",
      "    a_l = np.hstack((y_l, unk_l))\n",
      "    print A.shape, a_l.shape \n",
      "    \n",
      "    numL = L.shape[0]\n",
      "    \n",
      "    examples_file = open('svmlin.train.examples.%d'%numL, \"wb\")\n",
      "    labels_file = open('svmlin.train.labels.%d'%numL, \"wb\")\n",
      "    dump_svmlin(A, a_l, examples_file, labels_file)\n",
      "    \n",
      "    examples_file = open('svmlin.testL.examples.%d'%numL, \"wb\")\n",
      "    labels_file = open('svmlin.testL.labels.%d'%numL, \"wb\")\n",
      "    dump_svmlin(L, y_l, examples_file, labels_file)\n",
      "    \n",
      "    examples_file = open('svmlin.testU.examples.%d'%numL, \"wb\")\n",
      "    labels_file = open('svmlin.testU.labels.%d'%numL, \"wb\")\n",
      "    dump_svmlin(U, y_u, examples_file, labels_file)\n",
      "    \n",
      "    examples_file = open('svmlin.testHO.examples.%d'%numL, \"wb\")\n",
      "    labels_file = open('svmlin.testHO.labels.%d'%numL, \"wb\")\n",
      "    dump_svmlin(HO, y_ho, examples_file, labels_file)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def print_universvm_infiles(L, y_l, U, y_u, HO, y_ho):\n",
      "    A = scipy.sparse.vstack((L,U))\n",
      "    unk_l = y_u*0 - 3\n",
      "    a_l = np.hstack((y_l, unk_l))\n",
      "        \n",
      "    print A.shape, a_l.shape \n",
      "    numL = L.shape[0]\n",
      "    \n",
      "    training_file = 'universvm.train.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(A,a_l,training_file,zero_based=False)\n",
      "    \n",
      "    testL_file = 'universvm.testL.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(L,y_l,testL_file,zero_based=False)\n",
      "    \n",
      "    testU_file = 'universvm.testU.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(U,y_u,testU_file,zero_based=False)\n",
      "    \n",
      "    testHO_file = 'universvm.testHO.%d'%numL\n",
      "    sklearn.datasets.dump_svmlight_file(HO,y_ho,testHO_file,zero_based=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_sizes = [0.0025, 0.005, 0.01, 0.04, 0.08]\n",
      "for U_size in split_sizes:\n",
      "    splits = sklearn.cross_validation.StratifiedShuffleSplit(train_labels, n_iter=1, test_size=1-U_size)\n",
      "    labeled_indices, unlabeled_indices = splits.__iter__().next()\n",
      "\n",
      "    \n",
      "    L = X_train[labeled_indices]\n",
      "    L_ids = instance_ids[labeled_indices]\n",
      "\n",
      "    U = X_train[unlabeled_indices]\n",
      "    U_ids = instance_ids[unlabeled_indices]\n",
      "\n",
      "    y_l = train_labels[labeled_indices]\n",
      "    y_u = train_labels[unlabeled_indices]\n",
      "\n",
      "    print X_train.shape, L.shape, U.shape, X_test.shape\n",
      "   \n",
      "    print_universvm_infiles(L, y_l, U, y_u, X_test, test_labels)\n",
      "    print_svmlin_infiles(L, y_l, U, y_u, X_test, test_labels)\n",
      "    print_svmlight_infiles(L, y_l, U, y_u, X_test, test_labels)\n",
      "\n",
      "\n",
      "    svm_small = sklearn.svm.LinearSVC(penalty='l2', C=10, dual=False)\n",
      "    svm_small.fit(L, y_l)\n",
      "    accuracy = sklearn.metrics.accuracy_score(test_labels, svm_small.predict(X_test))\n",
      "    print (1.0-accuracy)*100.0\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#TODO\n",
      "# repeat with svmlight, svmlin, and qn_s3vm\n",
      "# try again with NMF features / clusters\n",
      "#   can we cluster the docs effectively\n",
      "#   and use NMf / auto encoder features?\n",
      "# can we repeat with other data sets?\n",
      "#\n",
      "# can we find MMMF / Max Margin Clustering method?\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}